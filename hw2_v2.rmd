---
title: "Modern Data Mining, HW 2"
author:
- Group Member Christian Benitez
- Group Member Taurean Butler
- Group Member NA
date: 'Due: 11:59 PM,  Sunday, 02/12'
output:
  pdf_document:
    number_sections: yes
    toc: yes
    toc_depth: '4'
  html_document:
    code_folding: show
    highlight: haddock
    number_sections: yes
    theme: lumen
    toc: yes
    toc_depth: 4
    toc_float: yes
  word_document:
    toc: yes
    toc_depth: '4'
urlcolor: blue
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, fig.width=8, fig.height=4)
options(scipen = 0, digits = 3)  # controls base R output
# check if you have ISLR package, if not, install it
if(!require('pacman')) {install.packages('pacman')}
pacman::p_load(ISLR, tidyverse, data.table, dplyr, tidyselect, skimr, corrplot, ggbiplot,factoextra,GGally,ggpubr,cluster) # add the packages needed
```


\pagebreak

# Overview {-}

Principle Component Analysis is widely used in data exploration, dimension reduction, data visualization. The aim is to transform original data into uncorrelated linear combinations of the original data while keeping the information contained in the data. High dimensional data tends to show clusters in lower dimensional view. 

Clustering Analysis is another form of EDA. Here we are hoping to group data points which are close to each other within the groups and far away between different groups. Clustering using PC's can be effective. Clustering analysis can be very subjective in the way we need to summarize the properties within each group. 

Both PCA and Clustering Analysis are so called unsupervised learning. There is no response variables involved in the process. 

For supervised learning, we try to find out how does a set of predictors relate to some response variable of the interest. Multiple regression is still by far, one of the most popular methods. We use a linear models as a working model for its simplicity and interpretability. It is important that we use domain knowledge as much as we can to determine the form of the response as well as the function format of the factors on the other hand. 


## Objectives

- PCA
- SVD
- Clustering Analysis
- Linear Regression

## Review materials

- Study Module 2: PCA
- Study Module 3: Clustering Analysis
- Study Module 4: Multiple regression

## Data needed

- `NLSY79.csv`
- `brca_subtype.csv`
- `brca_x_patient.csv`

# Case study 1: Self-seteem 

Self-esteem generally describes a person's overall sense of self-worthiness and personal value. It can play significant role in one's motivation and success throughout the life. Factors that influence self-esteem can be inner thinking, health condition, age, life experiences etc. We will try to identify possible factors in our data that are related to the level of self-esteem. 

In the well-cited National Longitudinal Study of Youth (NLSY79), it follows about 13,000 individuals and numerous individual-year information has been gathered through surveys. The survey data is open to public [here](https://www.nlsinfo.org/investigator/). Among many variables we assembled a subset of variables including personal demographic variables in different years, household environment in 79, ASVAB test Scores in 81 and Self-Esteem scores in 81 and 87 respectively. 

The data is store in `NLSY79.csv`.



Here are the description of variables:

**Personal Demographic Variables**

* Gender: a factor with levels "female" and "male"
* Education05: years of education completed by 2005
* HeightFeet05, HeightInch05: height measurement. For example, a person of 5'10 will be recorded as HeightFeet05=5, HeightInch05=10.
* Weight05: weight in lbs.
* Income87, Income05: total annual income from wages and salary in 2005. 
* Job87 (missing), Job05: job type in 1987 and 2005, including Protective Service Occupations, Food Preparation and Serving Related Occupations, Cleaning and Building Service Occupations, Entertainment Attendants and Related Workers, Funeral Related Occupations, Personal Care and Service Workers, Sales and Related Workers, Office and Administrative Support Workers, Farming, Fishing and Forestry Occupations, Construction Trade and Extraction Workers, Installation, Maintenance and Repairs Workers, Production and Operating Workers, Food Preparation Occupations, Setters, Operators and Tenders,  Transportation and Material Moving Workers
 
 
**Household Environment**
 
* Imagazine: a variable taking on the value 1 if anyone in the respondent’s household regularly read magazines in 1979, otherwise 0
* Inewspaper: a variable taking on the value 1 if anyone in the respondent’s household regularly read newspapers in 1979, otherwise 0
* Ilibrary: a variable taking on the value 1 if anyone in the respondent’s household had a library card in 1979, otherwise 0
* MotherEd: mother’s years of education
* FatherEd: father’s years of education
* FamilyIncome78

**Variables Related to ASVAB test Scores in 1981**

Test | Description
--------- | ------------------------------------------------------
AFQT | percentile score on the AFQT intelligence test in 1981 
Coding | score on the Coding Speed test in 1981
Auto | score on the Automotive and Shop test in 1981
Mechanic | score on the Mechanic test in 1981
Elec | score on the Electronics Information test in 1981
Science | score on the General Science test in 1981
Math | score on the Math test in 1981
Arith | score on the Arithmetic Reasoning test in 1981
Word | score on the Word Knowledge Test in 1981
Parag | score on the Paragraph Comprehension test in 1981
Numer | score on the Numerical Operations test in 1981

**Self-Esteem test 81 and 87**

We have two sets of self-esteem test, one in 1981 and the other in 1987. Each set has same 10 questions. 
They are labeled as `Esteem81` and `Esteem87` respectively followed by the question number.
For example, `Esteem81_1` is Esteem question 1 in 81.

The following 10 questions are answered as 1: strongly agree, 2: agree, 3: disagree, 4: strongly disagree

* Esteem 1: “I am a person of worth”
* Esteem 2: “I have a number of good qualities”
* Esteem 3: “I am inclined to feel like a failure”
* Esteem 4: “I do things as well as others”
* Esteem 5: “I do not have much to be proud of”
* Esteem 6: “I take a positive attitude towards myself and others”
* Esteem 7: “I am satisfied with myself”
* Esteem 8: “I wish I could have more respect for myself”
* Esteem 9: “I feel useless at times”
* Esteem 10: “I think I am no good at all”

## Data preparation

Load the data. Do a quick EDA to get familiar with the data set. Pay attention to the unit of each variable. Are there any missing values? 

> Applying the *which()* function, we find that there are no NA values in this data set, but there does appear to be blank values which have been removed. However, there are errors present,such as the variable HeightFeet05 having a negative value of -4 and the variable Income87 which has a value of -2.

```{r quick skim of the data}
getwd()
setwd(dir = "~/R_Projects/class-codes/Spring 2023/STAT5710/Homework/")
temp <- read.csv('HW2/data/NLSY79.csv', header = T, stringsAsFactors = F) %>%  filter(HeightFeet05 > 0, Income87 > 0, Job05 != "")

# missing values? real variables vs. factors? are varable values reasonable?
str(temp)
summary(temp)
levels(as.factor(temp$Job05))
table(as.factor(temp$Job05))
which(is.na(temp))
which(temp =="")
```


## Self esteem evaluation

Let concentrate on Esteem scores evaluated in 87. 

0. First do a quick summary over all the `Esteem` variables. Pay attention to missing values, any peculiar numbers etc. How do you fix problems discovered if there is any? Briefly describe what you have done for the data preparation. 

> In the data code above, we discovered that Job05 had several missing quantity values. For this dataset, we decided to remove participants that had any missing values since we still have a relatively large sample size still. We also noticed some variables had ranges that were weird. For example, the variable HeightFeet05 having a negative value of -4 and the variable Income87 which has a value of -2.

1. Reverse Esteem 1, 2, 4, 6, and 7 so that a higher score corresponds to higher self-esteem. (Hint: if we store the esteem data in `data.esteem`, then `data.esteem[,  c(1, 2, 4, 6, 7)]  <- 5 - data.esteem[,  c(1, 2, 4, 6, 7)]` to reverse the score.)

```{r}
data.esteem <- temp %>%  select(Esteem87_1:Esteem87_10)
data.esteem[,  c(1, 2, 4, 6, 7)]  <- 5 - data.esteem[,  c(1, 2, 4, 6, 7)]
data.esteem$Esteem87_1 <- as.integer(data.esteem$Esteem87_1)
data.esteem$Esteem87_2 <- as.integer(data.esteem$Esteem87_2)
data.esteem$Esteem87_4 <- as.integer(data.esteem$Esteem87_4)
data.esteem$Esteem87_6 <- as.integer(data.esteem$Esteem87_6)
data.esteem$Esteem87_7 <- as.integer(data.esteem$Esteem87_7)
```


2. Write a brief summary with necessary plots about the 10 esteem measurements.

> From a brief glance at the summary stats and histograms of the 10 esteem measurements, it appears that people in our population sample are typically more likely to report having higher self-esteem. This is shown by the data being skewed to the left and the means being around 3 or higher

```{r}
(data.esteem.summary <- data.esteem %>% skim() %>% 
                                        select(skim_variable, numeric.mean, numeric.sd, numeric.hist))
attach(data.esteem)
hist(Esteem87_1)
hist(Esteem87_2)
hist(Esteem87_3)
hist(Esteem87_4)
hist(Esteem87_5)
hist(Esteem87_6)
hist(Esteem87_7)
hist(Esteem87_8)
hist(Esteem87_9)
hist(Esteem87_10)
detach(data.esteem)
```


3. Do esteem scores all positively correlated? Report the pairwise correlation table and write a brief summary.

> Though some measure are weakly correlated with some Esteem measures then others, all variables are positively correlated with each other. 

```{r}
(data.esteem.cor <- cor(data.esteem))
corrplot::corrplot(data.esteem.cor, method = "number", type = "lower")
```


4. PCA on 10 esteem measurements. (centered but no scaling)

    a) Report the PC1 and PC2 loadings. Are they unit vectors? Are they orthogonal? 
    
    > PC1 and PC2 loadings are unit vectors. 
    
    > PC1 and PC2 loadings are correlated with each other. p val = 3e-05 and r = .95
    
```{r}
#Perfoming PCA Analysis with prcomp
(data.esteem.pc <- prcomp(data.esteem, center = T, scale. = F))
knitr::kable(data.esteem.pc$rotation[,c(1,2)])

round(t(data.esteem.pc$rotation) %*% data.esteem.pc$rotation)

round(cov(data.esteem.pc$rotation), 10) 

cor.test(data.esteem.pc$rotation[,1],data.esteem.pc$rotation[,2])
```
    
    b) Are there good interpretations for PC1 and PC2? (If loadings are all negative, take the positive loadings for the ease of interpretation)
    
    > PC1 are similar in magnitude; however, there does seem to be slightly higher weights across some other esteem variables. As an example Esteem87_1 is weighted at .226, while Esteem87_10 is weighted at .382, meaning that you should place more weight onto Esteem87_10. 
    > PC2 provides the second most variability and can implies that these self-esteem measures are characterized into two dimensions which are Esteem87_1 through Esteem87_7 and Esteem87_8 through Esteem87_10 
    
    c) How is the PC1 score obtained for each subject? Write down the formula.
    
    General Forumla = PCX = PCLoading11 * X1 + PCLoading21 * X2 ... PCLoadingx1*Xx 
    
   > PC1 = Estee87_1 X 0.226 + Estee87_2 X 0.239 + Estee87_3 X 0.280 + Estee87_4 X 0.251 + Estee87_5 X 0.307 + Estee87_6 X 0.317 + Estee87_7 X 0.301 + Estee87_8 X 0.395 + Estee87_9 X 0.403 + Estee87_10 X 0.382
   
     
    d) Are PC1 scores and PC2 scores in the data uncorrelated? 
    
    > PC1 and PC2 are uncorrelated t value = 8e-15 and r = 1.73e-16 
    
```{r}
round(t(data.esteem.pc$x) %*% data.esteem.pc$x)

round(cov(data.esteem.pc$x), 10) 

cor.test(data.esteem.pc$x[,1],data.esteem.pc$x[,2])
```
    
    e) Plot PVE (Proportion of Variance Explained) and summarize the plot. 
    
    >     The plot shown above gives us an idea of how much the variance can be explained by each PC. As can be seen by these graphs, the more PCs you add the higher the PVE goes. However, the first PCs explain more variance than the later ones. For example, PC1 seems to capture about .5 of the variance
    
```{r}
plot(summary(data.esteem.pc)$importance[2, ],
     ylab = "PVE",
     xlab = "PCs",
     main = "Scree Plot of PVE for Esteem Scores")


```
       
        f) Also plot CPVE (Cumulative Proportion of Variance Explained). What proportion of the variance in the data is explained by the first two principal components?
        
        >    The first two principal components capture about 59.5% of the variance
        
```{r}
plot(summary(data.esteem.pc)$importance[3, ], pch=16,
     ylab="Cumulative PVE",
     xlab="Number of PCs",
     main="Scree Plot of Cumulative PVE for AFQT")
```
        
        g) PC’s provide us with a low dimensional view of the self-esteem scores. Use a biplot with the first two PC's to display the data.  Give an interpretation of PC1 and PC2 from the plot. (try `ggbiplot` if you could, much prettier!)
    
    > PC1 provides us with information that the loadings are similar and with the same sign
    
    > PC2 provides us with the difference between Esteem87_1 through Esteem87_7 and Esteem87_8 through Esteem87_10 
    
```{r}
lim <- c(-.09, .09) 
biplot(data.esteem.pc, 
       xlim=lim,
       ylim=lim,
       main="Biplot of the PCs")
abline(v=0, h=0)

ggbiplot::ggbiplot(data.esteem.pc, obs.scale = 1, var.scale = 1, ellipse = TRUE,circle = TRUE) +
                  scale_color_discrete(name = '') +
                  theme(legend.direction = 'horizontal', legend.position = 'top')

```


```{r}
summary(select(temp,tidyselect::vars_select(names(temp), starts_with('Esteem87', ignore.case = TRUE))))
unique(select(temp,tidyselect::vars_select(names(temp), starts_with('Esteem87', ignore.case = TRUE))))
```


5. Apply k-means to cluster subjects on the original esteem scores

    a) Find a reasonable number of clusters using within sum of squared with elbow rules.
    
    > 2 or 3 sounds like a reasonable number of clusters, but lets go with two for this analysis
    
```{r}
factoextra::fviz_nbclust(data.esteem, kmeans, method = "wss")
```
    
     b) Can you summarize common features within each cluster?
     
     > If we were to apply 2 clusters on the data structure, then we see that the data is being split based on those who have high and low self-esteem, which is using PC1. There doesn't appear to be much variability in PC2. As can be seen, Cluster 2 shows individuals with higher mean self esteem, higher income, and higher education and intelligence.
     
```{r}
# Two Clusters
data.esteem.kmeans_02 <- kmeans(data.esteem, centers = 2)

temp <- temp %>% mutate(cluster = data.esteem.kmeans_02$cluster) %>% rowwise() %>% mutate(m = mean(Esteem87_1:Esteem87_10))

temp$cluster <- as.factor(temp$cluster)

temp %>% group_by(cluster) %>% 
        dplyr::summarise(n = n(),
               mean_ES87 = mean(m),
               min_esteem = min(m),
               max_esteem = max(m),
               median = median(m),
               mean_weight = mean(Weight05),
               mean_income = mean(Income87),
               mean_ed = mean(Education05),
               mean_AFQT = mean(AFQT))

```
     
    
    c) Can you visualize the clusters with somewhat clear boundaries? You may try different pairs of variables and different PC pairs of the esteem scores.
    
```{r}
data.frame(pc1 = data.esteem.pc$x[, 1], 
             pc2 = data.esteem.pc$x[, 2],
             group = as.factor(data.esteem.kmeans_02$cluster)) %>%
  ggplot(aes(x = pc1, y = pc2, col = group)) +
  geom_point() +
  ggtitle("Clustering over PC1 and PC2") 
```
    


6. We now try to find out what factors are related to self-esteem? PC1 of all the Esteem scores is a good variable to summarize one's esteem scores. We take PC1 as our response variable. 

    a) Prepare possible factors/variables:
    
      - EDA the data set first. 

      - Personal information: gender, education (05), log(income) in 87, job type in 87. Weight05 (lb) and HeightFeet05 together with Heightinch05. One way to summarize one's weight and height is via Body Mass Index which is defined as the body mass divided by the square of the body height, and is universally expressed in units of kg/m². Note, you need to create BMI first. Then may include it as one possible predictor. 
      
```{r}
demographics <- temp %>% select(Subject, Gender, Education05, Income87, Job05, Weight05, HeightFeet05,HeightInch05,Imagazine,Inewspaper,Ilibrary,MotherEd,FatherEd,FamilyIncome78) %>% 
                        mutate(income_log = log(Income87), height = (HeightInch05 + HeightFeet05*12)*.0254,weight_kg = Weight05*0.4536, bmi = weight_kg/(height^2))
```
      
          
      - Household environment: Imagazine, Inewspaper, Ilibrary, MotherEd, FatherEd, FamilyIncome78. Do set indicators `Imagazine`, `Inewspaper` and `Ilibrary` as factors. 
      
```{r}
esteem$Ilibrary <- as.factor(esteem$Ilibrary)
esteem$Imagazine <- as.factor(esteem$Imagazine)
esteem$Inewspaper <- as.factor(esteem$Inewspaper)
```
      
    
      - You may use PC1 of ASVAB as level of intelligence
      
```{r}
data.asvab.pc <- temp %>% select(Science:Elec) %>% prcomp(center = T, scale. = T) 
knitr::kable(data.asvab.pc$x[1:5,])

ASVAB <- data.asvab.pc$x[,1]

self_esteem <- data.esteem.pc$x[,1]%>%  as.data.frame()

esteem <- cbind(demographics,ASVAB, self_esteem)

colnames(esteem)[19] <- "ASVAB"
colnames(esteem)[20] <- "self_esteem"
```
      
      Summary of our Data 
      
```{r}
names(esteem)
dim(esteem)
str(esteem)
summary(esteem)
skim(esteem)
```
      
        
    b)   Run a few regression models between PC1 of all the esteem scores and suitable variables listed in a). Find a final best model with your own criterion. 
    
```{r}
esteem.lm <- as.formula(paste('self_esteem ~', esteem %>% dplyr::select(-c(self_esteem,Subject)) %>%  names() %>% paste(., collapse='+')))
demographics.lm <- lm(esteem.lm, data = esteem) 
summary(demographics.lm)

car::Anova(demographics.lm)
```
    
```{r}
esteem.lm2 <- as.formula(paste('self_esteem ~', esteem %>% dplyr::select(Education05,Job05,income_log,ASVAB) %>%  names() %>% paste(., collapse='+')))
demographics.lm2 <- lm(esteem.lm2, data = esteem) 
summary(demographics.lm2)
car::Anova(demographics.lm2)

```
      
            - How did you land this model? Run a model diagnosis to see if the linear model assumptions are reasonably met. 
            
            
```{r}
plot(demographics.lm,c(1:2))
plot(demographics.lm2, c(1:2))
```
      
        
      - Write a summary of your findings. In particular, explain what and how the variables in the model affect one's self-esteem. 
        
        > First, we started by mapping all variables into a single model. Some variables were found to be significant, while others not. The most notable include these variables
        
        - Income_log ()
        - Education05
        - ASVAB
        - Job05: 
        
Job051300 TO 1560: Engineers, Architects, Surveyers, Engineering and Related Technicians  -0.6043     0.1901   -3.18  0.00150
Job051600 TO 1760: Physical Scientists                                                    -1.4246     0.6140   -2.32  0.02042
Job053300 TO 3650: Health Care Technical and Support Occupations                          -0.6008     0.1531   -3.92  9.0e-05
Job054200 TO 4250: Cleaning and Building Service Occupations                              -0.4515     0.1887   -2.39  0.01683
Job054300 TO 4430: Entertainment Attendants and Related Workers                           -1.0706     0.4134   -2.59  0.00968
Job056200 TO 6940: Construction Trade and Extraction Workers                              -0.3457     0.1379   -2.51  0.01224
Job057000 TO 7620: Installation, Maintenance and Repairs Workers                          -0.2955     0.1433   -2.06  0.03930
Job059000 TO 9750: Transportation and Material Moving Workers                             -0.4719     0.1409   -3.35  0.00083

        > Given these variables, self-esteem may be impacted by education, income and ASVAB. These are all positive correlations suggesting that higher education, income and intelligence as measured by ASVAB all increase one's self-esteem. For jobs, it seems like these jobs are all negativly related to self-esteem. When inspecting further, it's possible some of these jobs are demanding, but not seen in the highest esteem. Other professions may be impacted by the pressure to perform in a given field, which may be difficult to catch up with the market.


# Case study 2: Breast cancer sub-type


[The Cancer Genome Atlas (TCGA)](https://www.cancer.gov/about-nci/organization/ccg/research/structural-genomics/tcga), a landmark cancer genomics program by National Cancer Institute (NCI), molecularly characterized over 20,000 primary cancer and matched normal samples spanning 33 cancer types. The genome data is open to public from the [Genomic Data Commons Data Portal (GDC)](https://portal.gdc.cancer.gov/).
 
In this study, we focus on 4 sub-types of breast cancer (BRCA): basal-like (basal), Luminal A-like (lumA), Luminal B-like (lumB), HER2-enriched. The sub-type is based on PAM50, a clinical-grade luminal-basal classifier. 

* Luminal A cancers are low-grade, tend to grow slowly and have the best prognosis.
* Luminal B cancers generally grow slightly faster than luminal A cancers and their prognosis is slightly worse.
* HER2-enriched cancers tend to grow faster than luminal cancers and can have a worse prognosis, but they are often successfully treated with targeted therapies aimed at the HER2 protein. 
* Basal-like breast cancers or triple negative breast cancers do not have the three receptors that the other sub-types have so have fewer treatment options.

We will try to use mRNA expression data alone without the labels to classify 4 sub-types. Classification without labels or prediction without outcomes is called unsupervised learning. We will use K-means and spectrum clustering to cluster the mRNA data and see whether the sub-type can be separated through mRNA data.

We first read the data using `data.table::fread()` which is a faster way to read in big data than `read.csv()`. 

```{r}
setwd(dir = "/Users/christianbenitez/R_Projects/class-codes/Spring 2023/STAT5710/Homework/HW2/")


brca <- fread("data/brca_subtype.csv")

# get the sub-type information
brca_subtype <- brca$BRCA_Subtype_PAM50

```

1. Summary and transformation

    a) How many patients are there in each sub-type? 
    
```{r}
brca$BRCA_Subtype_PAM50 <- as.factor(brca$BRCA_Subtype_PAM50)
table(brca$BRCA_Subtype_PAM50)
brca %>% group_by(BRCA_Subtype_PAM50) %>%
        dplyr::summarise(n = n())
#brca <- brca[,-1]
```
    

    b) Randomly pick 5 genes and plot the histogram by each sub-type.
    
```{r}
set.seed(11)
(genes <- sample(names(brca),5,replace = FALSE))

brca %>% select(genes,BRCA_Subtype_PAM50) %>% 
        pivot_longer(!BRCA_Subtype_PAM50,names_to = "genes") %>% 
         ggplot(aes(x = value, y = ..density..)) +
                geom_histogram(aes(fill = genes)) +
                facet_wrap(~BRCA_Subtype_PAM50, scales = "free") +
                theme_bw()

brca %>% select(genes,BRCA_Subtype_PAM50) %>% 
        pivot_longer(!BRCA_Subtype_PAM50,names_to = "genes") %>% 
         ggplot(aes(x = value, y = ..density..)) +
                geom_histogram(aes(fill = genes), position = "identity") +
                facet_wrap(genes~BRCA_Subtype_PAM50, scales = "free") +
                theme_bw()


```
    
    c) Remove gene with zero count and no variability. Then apply logarithmic transform.
    
```{r}
brca <- brca[,-1]
sel_cols <- which(colSums(abs(brca)) != 0)
brca_sub <- brca[, sel_cols, with=F]
#dim(brca_sub)
brca_sub <- log2(as.matrix(brca_sub+1e-10))
```


2. Apply kmeans on the transformed dataset with 4 centers and output the discrepancy table between the real sub-type `brca_subtype` and the cluster labels.

```{r}
brca_sub_kmeans <- kmeans(x = brca_sub, 4)
table(brca_subtype, brca_sub_kmeans$cluster)
```


3. Spectrum clustering: to scale or not to scale?

    a) Apply PCA on the centered and scaled dataset. How many PCs should we use and why? You are encouraged to use `irlba::irlba()`.
    
   >  Based on the pot shown below, we can say that this dataset may use 4 PCs. This is in part due to the scree plot having a significantly larger dip between 3-4 than 2-3/
    
```{r}
## First Scaling and Centering the Data
brca_sub_scaled_centered <- scale(as.matrix(brca_sub), center = T, scale = T)
numgenes <-ncol(brca_sub_scaled_centered)
## Applying the irlba function instead of prcomp
svd_ret <- irlba::irlba(brca_sub_scaled_centered, nv = 10)
#names(brca_ret)

## Figuring out how many PCs we need
svd_var <- svd_ret$d^2/(nrow(brca_sub_scaled_centered)-1)
svd_apx <- svd_var/numgenes
plot(svd_apx, type="b", pch = 19, frame = FALSE)

```
     
      b) Plot PC1 vs PC2 of the centered and scaled data and PC1 vs PC2 of the centered but unscaled data side by side. Should we scale or not scale for clustering process? Why? (Hint: to put plots side by side, use `gridExtra::grid.arrange()` or `ggpubr::ggrrange()` or `egg::ggrrange()` for ggplots; use `fig.show="hold"` as chunk option for base plots)
      
```{r}
## Centering Data but not Scaling
svd_ret_unscaled <- scale(as.matrix(brca_sub), center = T, scale = F)

## Applying the irlba function instead of prcomp
svd_ret_unscaled <- irlba::irlba(svd_ret_unscaled, nv = 10)
#names(brca_ret_unscaled)

## Figuring out how many PCs we need
svd_var_unscaled <- svd_ret_unscaled$d^2/(nrow(svd_ret_unscaled)-1)
svd_apx_unscaled <- svd_var_unscaled/numgenes

plot(brca_apx_unscaled, type="b", pch = 19, frame = FALSE)
```
      
    
```{r}

# Possibly 4 PCs maybe be good based on the Plot Lets save those scores
pc_score_scaled <- (svd_ret$u[, 1:4])*(svd_ret$d[1:4])
# Possibly 4 PCs maybe be good based on the Plot Lets scave those scores
pc_score_unscaled <- (svd_ret_unscaled$u[, 1:4])*(svd_ret_unscaled$d[1:4])
```
    
    
    b) Plot PC1 vs PC2 of the centered and scaled data and PC1 vs PC2 of the centered but unscaled data side by side. Should we scale or not scale for clustering process? Why? (Hint: to put plots side by side, use `gridExtra::grid.arrange()` or `ggpubr::ggrrange()` or `egg::ggrrange()` for ggplots; use `fig.show="hold"` as chunk option for base plots)
    
```{r}
# Plotting PC 1 and PC2 That are centered and scaled
p_scaled_centered <- data.table(x = pc_score[,1], 
                y = pc_score[,2])%>%
  ggplot() + 
  geom_point(aes(x = x, y = y, col = as.factor(brca_subtype))) +
  ggtitle("Scaled and Centered") +
  theme_bw() +
  xlab("PC1") +
  labs(color = "Cancer Type") +
  ylab("PC2")
p_scaled_centered


# Plotting PC 1 and PC2 That are centered and unscaled
p_unscaled_centered <- data.table(x = pc_score_unscaled[,1], 
                y = pc_score_unscaled[,2])%>%
  ggplot() + 
  geom_point(aes(x = x, y = y, col = as.factor(brca_subtype))) +
  ggtitle("Unscaled and Centered") +
  labs(color = "Cancer Type") +
  theme_bw() +
  xlab("PC1") +
  ylab("PC2")
p_unscaled_centered


# Putting both in a model
ggpubr::ggarrange(p_scaled_centered, p_unscaled_centered)
```
    
    4. Spectrum clustering: center but do not scale the data

    a) Use the first 4 PCs of the centered and unscaled data and apply kmeans. Find a reasonable number of clusters using within sum of squared with the elbow rule.
    
    - Based on the Elbow Rule, it seems like this data can be split into 4 clusters
    
    ```{r}
# Plot That's Manually Done
k.values <- 1:10

wss <- function(df, k) {
  kmeans(df, k, nstart = 10)$tot.withinss
}
wss_values <- map_dbl(k.values, function(k) wss(pc_score_unscaled, k))
plot(k.values, wss_values,
       type="b", pch = 19, frame = FALSE, 
       xlab="Number of clusters K",
       ylab="Total within-clusters sum of squares")


# Plot usinf fviz_nbclust
fviz_nbclust(pc_score_unscaled, kmeans, method = "wss")

```
    
        b) Choose an optimal cluster number and apply kmeans. Compare the real sub-type and the clustering label as follows: Plot scatter plot of PC1 vs PC2. Use point color to indicate the true cancer type and point shape to indicate the clustering label. Plot the kmeans centroids with black dots. Summarize how good is clustering results compared to the real sub-type.
    
        
    > We will apply 4 clusters onto our kmeans function. When doing this, we observe that Cluster 1 is able to properly denote Basal, but almost indistinguishable for the other three cluster types 
    
```{r}
# # Plotting PC 1 and PC2 Scaled and Centered with k clusters
# kmean_ret <- kmeans(x = pc_score, 4)
# 
# p_scaled_centered <- data.table(x = pc_score[,1], 
#                 y = pc_score[,2],
#                 col = as.factor(brca_subtype),
#                 cl = as.factor(kmean_ret$cluster)) %>%
#   ggplot() + 
#   geom_point(aes(x = x, y = y, col = col, shape = cl)) +
#   ggtitle("Scaled and Centered") +
#   scale_color_manual(values = scales::hue_pal()(4)) +
#   theme_bw() +
#   labs(color = "Cancer type", shape = "Cluster") +
#   xlab("PC1") +
#   ylab("PC2")
# p_scaled_centered


# Plotting PC 1 and PC2 Scaled and Centered with k clusters
kmean_ret_unscaled <- kmeans(x = pc_score_unscaled, 4)

p_unscaled_centered <- data.table(x = pc_score_unscaled[,1], 
                y = pc_score_unscaled[,2],
                col = as.factor(brca_subtype),
                cl = as.factor(kmean_ret_unscaled$cluster)) %>%
  ggplot() + 
  geom_point(aes(x = x, y = y, col = col, shape = cl)) +
  ggtitle("Unscaled and Centered") +
  scale_color_manual(values = scales::hue_pal()(4)) +
  theme_bw() +
  geom_point(aes(x = kmean_ret_unscaled$centers[1,1], y = kmean_ret_unscaled$centers[1,2]), size = 5, fill = "black", shape = 19) +
  geom_point(aes(x = kmean_ret_unscaled$centers[2,1], y = kmean_ret_unscaled$centers[2,2]), size = 5, fill = "black", shape = 17) +
  geom_point(aes(x = kmean_ret_unscaled$centers[3,1], y = kmean_ret_unscaled$centers[3,2]), size = 5, fill = "black", shape = 15) +
    geom_point(aes(x = kmean_ret_unscaled$centers[4,1], y = kmean_ret_unscaled$centers[4,2]), size = 5, fill = "black", shape = 3) +
  labs(color = "Cancer type", shape = "Cluster") +
  xlab("PC1") +
  ylab("PC2")
p_unscaled_centered

# ggpubr::ggarrange(p_scaled_centered, p_unscaled_centered)
```
    
    c) Compare the clustering result from applying kmeans to the original data and the clustering result from applying kmeans to 4 PCs. Does PCA help in kmeans clustering? What might be the reasons if PCA helps?
    
    The goal of KMeans clustering is to minimize the total within cluster sum of squares. PCA does a really good job at that! As you can see when applying PCA, the WithinSS is much smaller comparatively to the original data set. 
    
```{r}
table(brca_subtype,brca_sub_kmeans$cluster)
  brca_sub_kmeans$withinss
table(brca_subtype,kmean_ret_unscaled$cluster)
  kmean_ret_unscaled$withinss
```

    
    d) Now we have an x patient with breast cancer but with unknown sub-type. We have this patient's mRNA sequencing data. Project this x patient to the space of PC1 and PC2. (Hint: remember we remove some gene with no counts or no variablity, take log and centered) Plot this patient in the plot in iv) with a black dot. Calculate the Euclidean distance between this patient and each of centroid of the cluster. Can you tell which sub-type this patient might have? 
    
    > Patient X seems to belon to cluster 3 which is more in line with the subtype for LumA
    
```{r}
setwd(dir = "/Users/christianbenitez/R_Projects/class-codes/Spring 2023/STAT5710/Homework/HW2/")
x_patient <- fread("data/brca_x_patient.csv") 

column_names<-intersect(colnames(x_patient), colnames(brca_sub))

x_patient %>% dplyr::select(column_names)

sel_cols <- which(x_patient != 0)

x_patient_sub <- x_patient[, sel_cols, with=F]

x_patient_sub <- log2(as.matrix(x_patient_sub+1e-10))



## First Scaling and Centering the Data
column_names<-intersect(colnames(x_patient_sub), colnames(brca_sub_center))
brca_sub_center = brca_sub[,column_names]



x_patient_centered<-data.frame(t(scale(as.matrix(rbind(x_patient_sub,brca_sub_center)), center = T, scale = F)[1161,]))


indexing <- match(column_names, colnames(brca_sub))

  
x_scores <- as.matrix(x_patient_centered[1,]) %*% as.matrix(svd_ret_unscaled$v[indexing,])

p_unscaled_centered <- data.table(x = pc_score_unscaled[,1], 
                y = pc_score_unscaled[,2],
                col = as.factor(brca_subtype),
                cl = as.factor(kmean_ret_unscaled$cluster)) %>%
  ggplot() + 
  geom_point(aes(x = x, y = y, color = cl)) +
  ggtitle("Unscaled and Centered") +
  scale_color_manual(values = scales::hue_pal()(4)) +
  theme_bw() +
  geom_point(aes(x = kmean_ret_unscaled$centers[1,1], y = kmean_ret_unscaled$centers[1,2]), size = 5, fill = "black", shape = 19) +
  geom_point(aes(x = kmean_ret_unscaled$centers[2,1], y = kmean_ret_unscaled$centers[2,2]), size = 5, fill = "black", shape = 17) +
  geom_point(aes(x = kmean_ret_unscaled$centers[3,1], y = kmean_ret_unscaled$centers[3,2]), size = 5, fill = "black", shape = 15) +
  geom_point(aes(x = kmean_ret_unscaled$centers[4,1], y = kmean_ret_unscaled$centers[4,2]), size = 5, fill = "black", shape = 3) +
  geom_text(aes(x = c(x_scores[1,1]),y= c(x_scores[1,2]),label = "Patient X"), size = 7)+
    labs(color = "Cancer type", shape = "Cluster") +
  xlab("PC1") +
  ylab("PC2")
p_unscaled_centered

```

```{r}
centers=as.data.frame(kmean_ret_unscaled$centers[, 1:2])
dist_df <- rbind(x_scores[1:4], centers)

dist <- round(dist(dist_df, method = "euclidean")[1:4],2)
cluster_labs <- c("Cluster 1", "Cluster 2", "Cluster 3", "Cluster 4")

knitr::kable(rbind(dist, cluster_labs))
```



# Case study 3: Auto data set

This question utilizes the `Auto` dataset from ISLR. The original dataset contains 408 observations about cars. It is similar to the CARS dataset that we use in our lectures. To get the data, first install the package ISLR. The `Auto` dataset should be loaded automatically. We'll use this dataset to practice the methods learn so far. 
Original data source is here: https://archive.ics.uci.edu/ml/datasets/auto+mpg

Get familiar with this dataset first. Tip: you can use the command `?ISLR::Auto` to view a description of the dataset. 

## EDA
Explore the data, with particular focus on pairwise plots and summary statistics. Briefly summarize your findings and any peculiarities in the data.


## What effect does `time` have on `MPG`?

a) Start with a simple regression of `mpg` vs. `year` and report R's `summary` output. Is `year` a significant variable at the .05 level? State what effect `year` has on `mpg`, if any, according to this model. 

b) Add `horsepower` on top of the variable `year` to your linear model. Is `year` still a significant variable at the .05 level? Give a precise interpretation of the `year`'s effect found here. 

c) The two 95% CI's for the coefficient of year differ among (i) and (ii). How would you explain the difference to a non-statistician?

d) Create a model with interaction by fitting `lm(mpg ~ year * horsepower)`. Is the interaction effect significant at .05 level? Explain the year effect (if any). 

## Categorical predictors

Remember that the same variable can play different roles! Take a quick look at the variable `cylinders`, and try to use this variable in the following analyses wisely. We all agree that a larger number of cylinders will lower mpg. However, we can interpret `cylinders` as either a continuous (numeric) variable or a categorical variable.

a) Fit a model that treats `cylinders` as a continuous/numeric variable. Is `cylinders` significant at the 0.01 level? What effect does `cylinders` play in this model?

b) Fit a model that treats `cylinders` as a categorical/factor. Is `cylinders` significant at the .01 level? What is the effect of `cylinders` in this model? Describe the `cylinders` effect over `mpg`. 

c) What are the fundamental differences between treating `cylinders` as a continuous and categorical variable in your models? 

d) Can you test the null hypothesis: fit0: `mpg` is linear in `cylinders` vs. fit1: `mpg` relates to `cylinders` as a categorical variable at .01 level?  


## Results

Final modeling question: we want to explore the effects of each feature as best as possible. You may explore interactions, feature transformations, higher order terms, or other strategies within reason. The model(s) should be as parsimonious (simple) as possible unless the gain in accuracy is significant from your point of view.
  
a) Describe the final model. Include diagnostic plots with particular focus on the model residuals and diagnoses.

b) Summarize the effects found.

c) Predict the `mpg` of the following car: A red car built in the US in 1983 that is 180 inches long, has eight cylinders, displaces 350 cu. inches, weighs 4000 pounds, and has a horsepower of 260. Also give a 95% CI for your prediction.


# Simple Regression through simulations
    
## Linear model through simulations

This exercise is designed to help you understand the linear model using simulations. In this exercise, we will generate $(x_i, y_i)$ pairs so that all linear model assumptions are met.

Presume that $\mathbf{x}$ and $\mathbf{y}$ are linearly related with a normal error $\boldsymbol{\varepsilon}$ , such that $\mathbf{y} = 1 + 1.2\mathbf{x} + \boldsymbol{\varepsilon}$. The standard deviation of the error $\varepsilon_i$ is $\sigma = 2$. 

We can create a sample input vector ($n = 40$) for $\mathbf{x}$ with the following code:

```{r, eval = F, echo = TRUE}
# Generates a vector of size 40 with equally spaced values between 0 and 1, inclusive
x <- seq(0, 1, length = 40)
```


### Generate data

Create a corresponding output vector for $\mathbf{y}$ according to the equation given above. Use `set.seed(1)`. Then, create a scatterplot with $(x_i, y_i)$ pairs. Base R plotting is acceptable, but if you can, please attempt to use `ggplot2` to create the plot. Make sure to have clear labels and sensible titles on your plots.

```{r}
set.seed(1)
xi <- seq(0, 1, length = 40)
error <- rnorm(40, mean = 0, sd = 2)
yi <-1+(1.2*x)+error

simdata <- as.data.frame(cbind(xi,yi))

g <- ggplot(simdata,aes(x = xi , y = yi)) + 
      geom_point() +
    labs(title = "Graph of Y = 1 + 1.2*X + error ", x = "Simulated X", y = "Simulated Y")

g
```



### Understand the model
i. Find the LS estimates of $\boldsymbol{\beta}_0$ and $\boldsymbol{\beta}_1$, using the `lm()` function. What are the true values of $\boldsymbol{\beta}_0$ and $\boldsymbol{\beta}_1$? Do the estimates look to be good? 

$\boldsymbol{\beta}_0$ is equal to 1.331. $\boldsymbol{\beta}_1$ is equal to .906.

```{r}
model1 <- lm(simdata$yi~simdata$xi)
summary(model1)
```


ii. What is your RSE for this linear model fit? Is it close to $\sigma = 2$? 

The residual standard error is 1.79, so it is close to $\sigma = 2$. This makes sense as most of our simulated error terms are going to be centered at zero with a standard deviation of two. The residual standard error is the measure of the standard deviation of the residuals.

ii. What is the 95% confidence interval for $\boldsymbol{\beta}_1$? Does this confidence interval capture the true $\boldsymbol{\beta}_1$?

```{r}
confint(model1)
```

The 95% confidence interval for $\boldsymbol{\beta}_1$, relationship between x on y, is [-1.034, 2.85]. The true confidence regression coefficient is present in the confidence interval. 

iii. Overlay the LS estimates and the true lines of the mean function onto a copy of the scatterplot you made above.

```{r}
g + 
    geom_smooth(method="lm", se = TRUE, level = 0.95, color = "red")  +
    geom_hline(yintercept = mean(simdata$yi, na.rm=TRUE), color = "blue") 
```


### diagnoses

i. Provide residual plot where fitted $\mathbf{y}$-values are on the x-axis and residuals are on the y-axis. 


```{r}
res <- resid(model1)

#produce residual vs. fitted plot
plot(fitted(model1), res)

#add a horizontal line at 0 
abline(0,0)

```


ii. Provide a normal QQ plot of the residuals.

```{r}
#create Q-Q plot for residuals
qqnorm(res)

#add a straight diagonal line to the plot
qqline(res) 
```

```{r}
plot(density(res))

```

iii. Comment on how well the model assumptions are met for the sample you used. 

The models residuals overall appear to display heteroscedasticity. The residuals are randomly scattered in our residual plot and there are no patterns to the residuals, the mean of the residuals appears to be at 0. However, the residuals don't follow a great normal distribution. They seemed to be skewed toward the don't appear to have normal distribution. The left has a longer tail and an odd shape. Though overall it is roughly bell shaped. A researcher may consider if they are comfortable with this in using regression. 



## Understand sampling distribution and confidence intervals

This part aims to help you understand the notion of sampling statistics and confidence intervals. Let's concentrate on estimating the slope only.  

Generate 100 samples of size $n = 40$, and estimate the slope coefficient from each sample. We include some sample code below, which should guide you in setting up the simulation. Note: this code is easier to follow but suboptimal; see the appendix for a more optimal R-like way to run this simulation.
```{r, eval = F, echo = TRUE}
# Inializing variables. Note b_1, upper_ci, lower_ci are vectors
x <- seq(0, 1, length = 40) 
n_sim <- 100              # number of simulations
b1 <- 0                   # n_sim many LS estimates of beta_1 (=1.2). Initialize to 0 for now
upper_ci <- 0             # upper bound for beta_1. Initialize to 0 for now.
lower_ci <- 0             # lower bound for beta_1. Initialize to 0 for now.
t_star <- qt(0.975, 38)   # Food for thought: why 38 instead of 40? What is t_star?

#ask Chris about should we be at .95 for qt versus the .975 given


```

```{r}
# Perform the simulation
for (i in 1:n_sim){
  y <- 1 + 1.2 * x + rnorm(40, sd = 2)
  lse <- lm(y ~ x)
  lse_output <- summary(lse)$coefficients
  se <- lse_output[2, 2]
  b1[i] <- lse_output[2, 1]
  upper_ci[i] <- b1[i] + t_star * se
  lower_ci[i] <- b1[i] - t_star * se
}
results <- as.data.frame(cbind(se, b1, upper_ci, lower_ci))

# remove unecessary variables from our workspace
rm(se, b1, upper_ci, lower_ci, x, n_sim, t_star, lse, lse_output) 

```





i. Summarize the LS estimates of $\boldsymbol{\beta}_1$ (stored in `results$b1`). Does the sampling distribution agree with theory? 

When we look at the summary statistics of  $\boldsymbol{\beta}_1$, we see that the distribution is approximately normal, potentially following a student T distribution. Additionally we see that the mean SE is approximately at 1.3, which is close to the slope set in our sample model of 1.2. Our simulation has standard deviation of 1.22. 

```{r}
plot(density(results$b1))
abline(v=mean(results$b1))
mean(results$b1)
sd(results$b1)
```

```{r}
set.seed(1)  # Set the seed for reproducible results
sims <- 100  # Set the number of simulations
n <- 40

for (i in 1:n_sim){

```




ii.  How many of your 95% confidence intervals capture the true $\boldsymbol{\beta}_1$? Display your confidence intervals graphically. 


```{r}

results$capture <- ifelse(results$b1 < results$upper_ci & results$b1 > results$lower_ci, 1, 0)
table(results$capture)

```




